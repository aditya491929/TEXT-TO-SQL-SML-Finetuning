{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c796208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install datasets transformers peft accelerate bitsandbytes sqlglot sqlite-utils tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71bdb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityamalwade/Desktop/NLP Final Project/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, sqlite3, io, zipfile, pathlib, random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "import sqlglot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a276c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spider_data/train_spider.json OK\n",
      "spider_data/dev.json OK\n",
      "spider_data/tables.json OK\n",
      "spider_data/database OK\n"
     ]
    }
   ],
   "source": [
    "SPIDER_DIR = Path(\"./spider_data\")  \n",
    "\n",
    "TRAIN_JSON  = SPIDER_DIR / \"train_spider.json\"\n",
    "TRAIN_OTHERS_JSON = SPIDER_DIR / \"train_others.json\"   \n",
    "DEV_JSON    = SPIDER_DIR / \"dev.json\"\n",
    "TABLES_JSON = SPIDER_DIR / \"tables.json\"\n",
    "DB_ROOT     = SPIDER_DIR / \"database\"  \n",
    "\n",
    "PREPARED_DIR = SPIDER_DIR.parent / \"prepared\"\n",
    "PREPARED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for p in [TRAIN_JSON, DEV_JSON, TABLES_JSON, DB_ROOT]:\n",
    "    print(p, \"OK\" if p.exists() else \"MISSING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d192a657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, ['perpetrator', 'college_2', 'flight_company', 'icfp_1', 'body_builder'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(TABLES_JSON, \"r\") as f:\n",
    "    TABLES = json.load(f)\n",
    "\n",
    "def build_schema_index(tables_json) -> Dict[str, dict]:\n",
    "    idx = {}\n",
    "    for db in tables_json:\n",
    "        db_id = db[\"db_id\"]\n",
    "        table_names = db[\"table_names_original\"]\n",
    "        columns = db[\"column_names_original\"]  # (table_idx, col_name)\n",
    "        column_types = db[\"column_types\"]\n",
    "        pks = set(db[\"primary_keys\"])          # column indices\n",
    "        fks = db[\"foreign_keys\"]               # list of [from_col_idx, to_col_idx]\n",
    "\n",
    "        tcols = {t:[] for t in table_names}\n",
    "        for col_idx, (t_i, c_name) in enumerate(columns):\n",
    "            if t_i == -1:  # special star row\n",
    "                continue\n",
    "            is_pk = col_idx in pks\n",
    "            tcols[table_names[t_i]].append((c_name, is_pk, column_types[col_idx]))\n",
    "\n",
    "        fk_pairs=[]\n",
    "        for fr, to in fks:\n",
    "            fr_ti, fr_col = columns[fr]\n",
    "            to_ti, to_col = columns[to]\n",
    "            if fr_ti==-1 or to_ti==-1:\n",
    "                continue\n",
    "            fk_pairs.append((table_names[fr_ti], fr_col, table_names[to_ti], to_col))\n",
    "\n",
    "        idx[db_id] = {\n",
    "            \"tables\": table_names,\n",
    "            \"tcols\": tcols,\n",
    "            \"fk_pairs\": fk_pairs\n",
    "        }\n",
    "    return idx\n",
    "\n",
    "SCHEMA_IDX = build_schema_index(TABLES)\n",
    "len(SCHEMA_IDX), list(SCHEMA_IDX)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b65448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: perpetrator\n",
      "Tables:\n",
      "  perpetrator(*Perpetrator_ID, People_ID, Date, Year, Location, Country, Killed, Injured)\n",
      "  people(*People_ID, Name, Height, Weight, Home Town)\n",
      "Foreign Keys:\n",
      "  perpetrator.People_ID -> people.People_ID\n"
     ]
    }
   ],
   "source": [
    "def serialize_schema(db_id: str, max_tables: int = 8, max_cols_per_table: int = 10) -> str:\n",
    "    s = SCHEMA_IDX[db_id]\n",
    "    tables = s[\"tables\"][:max_tables]\n",
    "    tcols  = s[\"tcols\"]\n",
    "    fk     = s[\"fk_pairs\"]\n",
    "\n",
    "    lines = [f\"Database: {db_id}\", \"Tables:\"]\n",
    "    for t in tables:\n",
    "        cols = tcols[t][:max_cols_per_table]\n",
    "        cols_str = \", \".join([(\"*\"+c if is_pk else c) for c,is_pk,_ in cols for c in [c]])\n",
    "        lines.append(f\"  {t}({cols_str})\")\n",
    "    if fk:\n",
    "        lines.append(\"Foreign Keys:\")\n",
    "        for (ft,fc,tt,tc) in fk[:12]:\n",
    "            lines.append(f\"  {ft}.{fc} -> {tt}.{tc}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "some_db = list(SCHEMA_IDX.keys())[0]\n",
    "print(serialize_schema(some_db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a27804",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTR = (\n",
    "\"You are a helpful assistant that writes correct SQL for the given question and database schema. \"\n",
    "\"Output ONLY the SQL query; do not include explanations.\"\n",
    ")\n",
    "\n",
    "def build_prompt(question: str, db_id: str) -> str:\n",
    "    schema_txt = serialize_schema(db_id)\n",
    "    return (\n",
    "f\"SYSTEM: {INSTR}\\n\"\n",
    "f\"USER:\\n\"\n",
    "f\"Question: {question}\\n\\n\"\n",
    "f\"Schema:\\n{schema_txt}\\n\\n\"\n",
    "f\"Rules:\\n\"\n",
    "f\"- Only use tables/columns from {db_id}.\\n\"\n",
    "f\"- Output only SQL, no commentary.\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ece4346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 1034, dict_keys(['db_id', 'question', 'prompt', 'sql_gold']))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_json_list(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_raw = load_json_list(TRAIN_JSON)\n",
    "dev_raw   = load_json_list(DEV_JSON)\n",
    "\n",
    "def to_examples(items):\n",
    "    rows=[]\n",
    "    for ex in items:\n",
    "        q   = ex[\"question\"]\n",
    "        sql = ex[\"query\"]  \n",
    "        db  = ex[\"db_id\"]\n",
    "        rows.append({\n",
    "            \"db_id\": db,\n",
    "            \"question\": q,\n",
    "            \"prompt\": build_prompt(q, db),\n",
    "            \"sql_gold\": sql\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "train_rows = to_examples(train_raw)\n",
    "dev_rows   = to_examples(dev_raw)\n",
    "\n",
    "len(train_rows), len(dev_rows), train_rows[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "146ce4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['db_id', 'question', 'prompt', 'sql_gold'],\n",
      "        num_rows: 7000\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['db_id', 'question', 'prompt', 'sql_gold'],\n",
      "        num_rows: 1034\n",
      "    })\n",
      "})\n",
      "SYSTEM: You are a helpful assistant that writes correct SQL for the given question and database schema. Output ONLY the SQL query; do not include explanations.\n",
      "USER:\n",
      "Question: How many heads of the departments are older than 56 ?\n",
      "\n",
      "Schema:\n",
      "Database: department_management\n",
      "Tables:\n",
      "  department(*Department_ID, Name, Creation, Ranking, Budget_in_Billions, Num_Employees)\n",
      "  head(*head_ID, name, born_state, age)\n",
      "  management(*department_ID, head_ID, temporary_acting)\n",
      "Foreign Keys:\n",
      "  management.head_ID - \n",
      "GOLD: SELECT count(*) FROM head WHERE age  >  56\n"
     ]
    }
   ],
   "source": [
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_rows),\n",
    "    \"dev\":   Dataset.from_list(dev_rows),\n",
    "})\n",
    "print(ds)\n",
    "print(ds[\"train\"][0][\"prompt\"][:500], \"\\nGOLD:\", ds[\"train\"][0][\"sql_gold\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761b2fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 118.73ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 280.43ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: prepared/spider_train.jsonl prepared/spider_dev.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = PREPARED_DIR\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_out = out / \"spider_train.jsonl\"\n",
    "dev_out   = out / \"spider_dev.jsonl\"\n",
    "\n",
    "ds[\"train\"].to_json(train_out, lines=True, orient=\"records\", force_ascii=False)\n",
    "ds[\"dev\"].to_json(dev_out,     lines=True, orient=\"records\", force_ascii=False)\n",
    "\n",
    "print(\"Wrote:\", train_out, dev_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371605a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlglot could not parse 0/50 dev gold queries\n",
      "Before: SELECT count(*) FROM singer\n",
      "After : SELECT COUNT(*) FROM singer\n"
     ]
    }
   ],
   "source": [
    "# Normalize SQL to a consistent style to make EM less sensitive to formatting\n",
    "def normalize_sql(s: str, dialect_in: str = \"mysql\", dialect_out: str = \"mysql\") -> str:\n",
    "    try:\n",
    "        return sqlglot.transpile(\n",
    "            s,\n",
    "            read=dialect_in,\n",
    "            write=dialect_out,\n",
    "            normalize=True,\n",
    "            pretty=False\n",
    "        )[0]\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "# Quick sanity: try to parse & normalize a small sample\n",
    "bad_parse = 0\n",
    "for i in range(50):\n",
    "    sql = ds[\"dev\"][i][\"sql_gold\"]\n",
    "    try:\n",
    "        _ = sqlglot.parse_one(sql)\n",
    "    except Exception:\n",
    "        bad_parse += 1\n",
    "print(f\"sqlglot could not parse {bad_parse}/50 dev gold queries\")\n",
    "\n",
    "print(\"Before:\", ds[\"dev\"][0][\"sql_gold\"])\n",
    "print(\"After :\", normalize_sql(ds[\"dev\"][0][\"sql_gold\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9610b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled prompt char lengths — min/avg/max: 476 925 1585\n",
      "SYSTEM: You are a helpful assistant that writes correct SQL for the given question and database schema. Output ONLY the SQL query; do not include explanations.\n",
      "USER:\n",
      "Question: What are the maximum and minimum budget of the departments?\n",
      "\n",
      "Schema:\n",
      "Database: department_management\n",
      "Tables:\n",
      "  department(*Department_ID, Name, Creation, Ranking, Budget_in_Billions, Num_Employees)\n",
      "  head(*head_ID, name, born_state, age)\n",
      "  management(*department_ID, head_ID, temporary_acting)\n",
      "Foreign Keys:\n",
      "  management.head_ID -> head.head_ID\n",
      "  management.department_ID -> department.Department_ID\n",
      "\n",
      "Rules:\n",
      "- Only use tables/columns from department_management.\n",
      "- Output only SQL, no commentary.\n",
      "\n",
      "\n",
      "GOLD: SELECT max(budget_in_billions) ,  min(budget_in_billions) FROM department\n"
     ]
    }
   ],
   "source": [
    "# Safer slice: get a dict-of-lists, then index the \"prompt\" list\n",
    "n = min(1000, len(ds[\"train\"]))\n",
    "subset = ds[\"train\"][:n]            # dict of lists\n",
    "prompts = subset[\"prompt\"]          # list of strings\n",
    "\n",
    "lens = [len(p) for p in prompts]\n",
    "print(\n",
    "    \"Sampled prompt char lengths — min/avg/max:\",\n",
    "    min(lens), sum(lens)//len(lens), max(lens)\n",
    ")\n",
    "\n",
    "# Peek at a full prompt+gold pair (row-wise access uses integer index)\n",
    "k = 3\n",
    "row = ds[\"train\"][k]                # single row dict\n",
    "print(row[\"prompt\"])\n",
    "print(\"\\nGOLD:\", row[\"sql_gold\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e7ab7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold SQL execution — OK: 20, Fail: 0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def run_sqlite(db_root: Path, db_id: str, sql: str):\n",
    "    db_path = db_root / db_id / f\"{db_id}.sqlite\"\n",
    "    con = sqlite3.connect(db_path.as_posix())\n",
    "    try:\n",
    "        df = pd.read_sql_query(sql, con)\n",
    "        return True, df\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "    finally:\n",
    "        con.close()\n",
    "\n",
    "# Test gold SQL executes for a few samples\n",
    "ok_cnt, fail_cnt = 0, 0\n",
    "errors = []\n",
    "for i in range(20):\n",
    "    ex = ds[\"dev\"][i]\n",
    "    ok, out = run_sqlite(DB_ROOT, ex[\"db_id\"], ex[\"sql_gold\"])\n",
    "    if ok:\n",
    "        ok_cnt += 1\n",
    "    else:\n",
    "        fail_cnt += 1\n",
    "        errors.append((ex[\"db_id\"], ex[\"question\"], out))\n",
    "\n",
    "print(f\"Gold SQL execution — OK: {ok_cnt}, Fail: {fail_cnt}\")\n",
    "if errors:\n",
    "    print(\"First error example:\\nDB:\", errors[0][0], \"\\nQ:\", errors[0][1], \"\\nErr:\", errors[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3aeb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
